{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome('C:/Users/User/Downloads/chromedriver')\n",
    "driver.implicitly_wait(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://pension.fss.or.kr/fss/consumer/flguide/beware/faq/view.jsp?schKey=TITLE&search.@CATEGORY3=&page=1&y=10&url=/fss/cm/1208250172921&bbsid=1208250172921&x=13&schValue=&search.@CATEGORY2=&idx=1524818741953&num=934&stitle=%BC%D2%BA%F1%C0%DA%BA%B8%C8%A3%BD%C7%C5%C2%C6%F2%B0%A1%20%B0%E1%B0%FA%B4%C2%20%BE%EE%B5%F0%BC%AD%20%C8%AE%C0%CE%C7%D2%20%BC%F6%20%C0%D6%B3%AA%BF%E4?'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQA():\n",
    "    item = {}\n",
    "    item['title'] = driver.find_element_by_class_name('title').get_attribute('innerHTML')\n",
    "    item['content'] = driver.find_element_by_class_name('contents').text.replace(\"\\n\", \"\")\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling():\n",
    "    page_xpath = '//*[@id=\"con_box\"]/table[2]/tbody/tr[1]/td/a'\n",
    "    items = []\n",
    "\n",
    "    for page in range(934):\n",
    "        items.append(getQA())\n",
    "        try:\n",
    "            driver.find_element_by_xpath(page_xpath).click()\n",
    "        except:\n",
    "            break\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "results = crawling()\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"--- 크롤링 수행 시간: %s seconds ---\" %(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results, columns=['title', 'content'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eunjeon import Mecab\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Hannanum\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "mecab = Mecab()\n",
    "okt = Okt()\n",
    "hannanum = Hannanum()\n",
    "komoran = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df.copy()\n",
    "\n",
    "# mecab\n",
    "tokenized['title_mecab'] = tokenized['title'].apply(lambda t : ' '.join(mecab.nouns(t)))\n",
    "tokenized['content_mecab'] = tokenized['content'].apply(lambda t : ' '.join(mecab.nouns(t)) if pd.notnull(t) else t)\n",
    "# okt(twitter)\n",
    "tokenized['title_okt'] = tokenized['title'].apply(lambda t : ' '.join(okt.nouns(t)))\n",
    "tokenized['content_okt'] = tokenized['content'].apply(lambda t : ' '.join(okt.nouns(t)) if pd.notnull(t) else t)\n",
    "# hannanum\n",
    "tokenized['title_hannanum'] = tokenized['title'].apply(lambda t : ' '.join(hannanum.nouns(t)))\n",
    "tokenized['content_hannanum'] = tokenized['content'].apply(lambda t : ' '.join(hannanum.nouns(t)) if pd.notnull(t) else t)\n",
    "# komoran\n",
    "tokenized['title_komoran'] = tokenized['title'].apply(lambda t : ' '.join(komoran.nouns(t)))\n",
    "tokenized['content_komoran'] = tokenized['content'].apply(lambda t : ' '.join(komoran.nouns(t)) if pd.notnull(t) else t)\n",
    "\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized.to_csv('results_tokenized.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aischool]",
   "language": "python",
   "name": "conda-env-aischool-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
